{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Anlysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Download COMPLETE\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import date, timedelta\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# importing list of stock tickers\n",
    "NASDAQ_tickers_list = pd.read_csv('nasdaq_tickers.csv')\n",
    "\n",
    "# getting dates to observe (past 30 days)\n",
    "todays_date = date.today()\n",
    "from_date = date.today() - timedelta(days=29)\n",
    "\n",
    "# creating dictionary to store dataframes\n",
    "stock_data = {}\n",
    "\n",
    "ticker_index = 1\n",
    "for stock in NASDAQ_tickers_list['Symbol']:\n",
    "    print(ticker_index, '/', len(NASDAQ_tickers_list['Symbol']), ' COMPLETED', sep=None)\n",
    "    try:\n",
    "        data = yf.download(stock, from_date, todays_date, progress=False)\n",
    "        if not data.empty:\n",
    "            stock_data[stock] = {\n",
    "                'Company Name': yf.Ticker(stock).info['longName'],\n",
    "                'Stock Data': data,\n",
    "                'Sharpe Ratio': -256,\n",
    "                'Treynor Ratio': -256\n",
    "            }\n",
    "            print(f'{stock} DOWNLOADED!')\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {stock}: {e}\")\n",
    "    clear_output(wait=True)\n",
    "    ticker_index += 1\n",
    "\n",
    "print('Stock Download COMPLETE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Sharpe Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNFRZ, Conifer Holdings, Inc.: 1.2172605715959994\n",
      "RPHM, Reneo Pharmaceuticals, Inc.: 0.9110002991219545\n",
      "CRMD, CorMedix Inc.: 0.8314883270081891\n",
      "PHUN, Phunware, Inc.: 0.6620343175346237\n",
      "NN, NextNav Inc.: 0.635982911466526\n",
      "MYRG, MYR Group Inc.: 0.5979175442587367\n",
      "LLYVA, Liberty Live Group: 0.5929089620659632\n",
      "LLYVK, Liberty Live Group: 0.589055580496083\n",
      "NCNO, nCino, Inc.: 0.5687561696138758\n",
      "PAYO, Payoneer Global Inc.: 0.5552994618334922\n",
      "LOGC, ContextLogic Inc.: 0.5532681497015639\n"
     ]
    }
   ],
   "source": [
    "# Getting risk-free rate\n",
    "treasury_ticker = \"^TNX\"\n",
    "treasury_data = yf.download(treasury_ticker, todays_date, progress=False)\n",
    "risk_free_rate = treasury_data['Close'].iloc[-1] / 100\n",
    "risk_free_rate_daily = risk_free_rate / 252\n",
    "\n",
    "# Calculating each the Sharpe Ratio for each stock\n",
    "for stock in stock_data:\n",
    "    stock_data[stock]['Stock Data']['Daily Return'] = stock_data[stock]['Stock Data']['Adj Close'].pct_change()\n",
    "    average_return = stock_data[stock]['Stock Data']['Daily Return'].mean()\n",
    "\n",
    "    std_dev_return = 0\n",
    "    if len(stock_data[stock]['Stock Data']['Daily Return'].array) > 1:  # Ensure there are enough data points\n",
    "        std_dev_return = stock_data[stock]['Stock Data']['Daily Return'].std()\n",
    "    else:\n",
    "        # print(f'ERROR - {stock}: Not enough information to calculate risk!')\n",
    "        continue\n",
    "\n",
    "    if std_dev_return == 0:\n",
    "        # print(f'{stock}: Consistent Close of 0 -- Skipping Sharpe Ratio calculation!')\n",
    "        continue\n",
    "\n",
    "    stock_data[stock]['Sharpe Ratio'] = (average_return - risk_free_rate_daily) / std_dev_return\n",
    "\n",
    "# Sorting and printing 10 highest Sharpe Ratio stocks\n",
    "stock_sorted_sharpe_ratio = dict(sorted(stock_data.items(), key=lambda item: item[1]['Sharpe Ratio'], reverse=True))\n",
    "for i, stock in enumerate(stock_sorted_sharpe_ratio):\n",
    "    if i > 10:\n",
    "        break\n",
    "    print(stock, ', ', stock_sorted_sharpe_ratio[stock]['Company Name'], ': ', stock_sorted_sharpe_ratio[stock]['Sharpe Ratio'], sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Treynor Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDTX, Cidara Therapeutics, Inc.: 1118.724298768857\n",
      "MYPS, PLAYSTUDIOS, Inc.: 18.644138844617682\n",
      "MDBH, MDB Capital Holdings, LLC: 11.248592554499691\n",
      "MTRX, Matrix Service Company: 9.458274607217998\n",
      "RFACU, RF Acquisition Corp.: 9.248116537310938\n",
      "GHIX, Gores Holdings IX, Inc.: 9.072573265642315\n",
      "PLAO, Patria Latin American Opportunity Acquisition Corp.: 7.686418901531902\n",
      "MOBX, Mobix Labs, Inc.: 7.25048681877758\n",
      "IVCP, Swiftmerge Acquisition Corp.: 6.989467875655463\n",
      "SWKHL, SWK Holdings Corporation 9.00% Senior Notes due 2027: 6.174865594882665\n",
      "FTII, FutureTech II Acquisition Corp.: 6.030620040890418\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Fetching market data\n",
    "market_data = yf.download('^GSPC', start=from_date, end=todays_date, progress=False)\n",
    "market_data['Daily Return'] = market_data['Adj Close'].pct_change().dropna()\n",
    "\n",
    "for stock in stock_data:\n",
    "    # Calculating beta\n",
    "    if len(stock_data[stock]['Stock Data']['Daily Return'].dropna()) != len(market_data['Daily Return'].dropna()):\n",
    "        continue\n",
    "\n",
    "    covariance = np.cov(stock_data[stock]['Stock Data']['Daily Return'].dropna(), market_data['Daily Return'].dropna())[0][1]\n",
    "    market_variance = np.var(market_data['Daily Return'])\n",
    "    beta = covariance / market_variance\n",
    "\n",
    "    if beta == 0:\n",
    "        continue\n",
    "    \n",
    "    # Calculating Treynor Ratio\n",
    "    stock_data[stock]['Treynor Ratio'] = (average_return - risk_free_rate) / beta\n",
    "\n",
    "stock_sorted_treynor_ratio = dict(sorted(stock_data.items(), key=lambda item: item[1]['Treynor Ratio'], reverse=True))\n",
    "for i, stock in enumerate(stock_sorted_treynor_ratio):\n",
    "    if i > 10:\n",
    "        break\n",
    "    print(stock, ', ', stock_sorted_treynor_ratio[stock]['Company Name'], ': ', stock_sorted_treynor_ratio[stock]['Treynor Ratio'], sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Sentiment Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NewsAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethanwright/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stock_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m NEWSAPI_KEY \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m81a66bfe85d7441bab96bbda4d1f1e0d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m newsapi \u001b[38;5;241m=\u001b[39m NewsApiClient(api_key\u001b[38;5;241m=\u001b[39mNEWSAPI_KEY)\n\u001b[1;32m      7\u001b[0m articles_by_name \u001b[38;5;241m=\u001b[39m newsapi\u001b[38;5;241m.\u001b[39mget_everything(\n\u001b[0;32m----> 8\u001b[0m     q\u001b[38;5;241m=\u001b[39m\u001b[43mstock_data\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPPL\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompany Name\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      9\u001b[0m     to\u001b[38;5;241m=\u001b[39mtodays_date\u001b[38;5;241m.\u001b[39misoformat(),\n\u001b[1;32m     10\u001b[0m     from_param\u001b[38;5;241m=\u001b[39mfrom_date\u001b[38;5;241m.\u001b[39misoformat(),\n\u001b[1;32m     11\u001b[0m     language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     sort_by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelevancy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m article \u001b[38;5;129;01min\u001b[39;00m articles_by_name[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marticles\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(article[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m article[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublishedAt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m article[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stock_data' is not defined"
     ]
    }
   ],
   "source": [
    "# limited to 100 calls every 24 hours (will take 40 days to get all news articles\n",
    "\n",
    "from newsapi import NewsApiClient\n",
    "NEWSAPI_KEY = '81a66bfe85d7441bab96bbda4d1f1e0d'\n",
    "newsapi = NewsApiClient(api_key=NEWSAPI_KEY)\n",
    "\n",
    "articles_by_name = newsapi.get_everything(\n",
    "    q=stock_data['APPL']['Company Name'],\n",
    "    to=todays_date.isoformat(),\n",
    "    from_param=from_date.isoformat(),\n",
    "    language=\"en\",\n",
    "    sort_by=\"relevancy\"\n",
    ")\n",
    "\n",
    "for article in articles_by_name['articles']:\n",
    "    print(article['title']+ ' | ' + article['publishedAt'] + ' | ' + article['url'])\n",
    "\n",
    "# for stock in stock_data:\n",
    "#     articles_by_name = newsapi.get_everything(\n",
    "#         q=stock_data[stock]['Company Name'],\n",
    "#         to = todays_date.isoformat(),\n",
    "#         from_param= from_date.isoformat(),\n",
    "#         language=\"en\",\n",
    "#         sort_by=\"relevancy\"\n",
    "#     )\n",
    "\n",
    "#     print(f'{stock}')\n",
    "#     for article in articles_by_name['articles']:\n",
    "#         print(article['title']+ ' | ' + article['publishedAt'] + ' | ' + article['url'])\n",
    "#     print('------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from twscrape import API, gather\n",
    "from twscrape.logger import set_log_level\n",
    "import csv\n",
    "\n",
    "api = API()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
